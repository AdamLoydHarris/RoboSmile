{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamLoydHarris/RoboSmile/blob/main/Notebooks/RoboSmile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a Jupyter notebook that guides you through the process of generating simulated patient data, fine-tuning a model using Google Generative AI (GEMINI), and evaluating the model's performance in assessing mental health states. The notebook is well-documented with explanatory comments to help you understand each step.\n",
        "\n",
        "Explanation:\n",
        "\n",
        "We start by installing the google-generativeai package, which provides access to Google's Generative AI models.\n",
        "We import necessary libraries:\n",
        "google.generativeai for interacting with the GEMINI API.\n",
        "pandas and numpy for data manipulation.\n",
        "tqdm for progress bars during data generation.\n",
        "We retrieve and configure the API key securely using a userdata module."
      ],
      "metadata": {
        "id": "pg8-WwHuFM39"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m8o12wr4I7cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2q43Nl1GFKI1",
        "outputId": "733ecef2-5416-4317-b34d-731101131158",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: better_profanity in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "# Install the google-generativeai package\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install -q --upgrade google-generativeai\n",
        "\n",
        "#!pip install profanity_check\n",
        "!pip install better_profanity\n",
        "\n",
        "# Import necessary libraries\n",
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "#import userdata  # Assuming you have a module to handle user data securely\n",
        "\n",
        "# Configure the API Key\n",
        "GOOGLE_API_KEY = 'AIzaSyCNyCdzpcNjEU2vFlhWpQIW0DZfFH_uqwE'\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Simulated Patient Data\n",
        "We'll generate a dataset of simulated patients with various mental health conditions and communication abilities.\n",
        "\n",
        "Explanation:\n",
        "\n",
        "We define a list of mental health conditions and communication levels.\n",
        "The generate_patient_response function creates a prompt for the GEMINI model to generate a patient's response based on the condition and communication level.\n",
        "We loop through each condition and communication level, generating 100 samples for each combination.\n",
        "The data is stored in a pandas DataFrame for easy manipulation."
      ],
      "metadata": {
        "id": "14CnVPICFaxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define mental health conditions and communication levels\n",
        "mental_health_conditions = [\n",
        "    'Depression',\n",
        "    'Anxiety',\n",
        "    'Bipolar Disorder',\n",
        "    'Schizophrenia',\n",
        "    'PTSD',\n",
        "    'OCD'\n",
        "]\n",
        "\n",
        "communication_levels = ['Low', 'Medium', 'High']\n",
        "\n",
        "\n",
        "#def generate_patient_response(condition, communication_level):\n",
        "#    prompt = f\"Patient with {condition} and communication level {communication_level}: How have you been feeling lately?\"\n",
        "#    response = model.generate_content(prompt)\n",
        "#    return response.text\n",
        "\n",
        "# Generate the dataset\n",
        "#data = []\n",
        "\n",
        "#for condition in tqdm(mental_health_conditions):\n",
        "#    for comm_level in communication_levels:\n",
        "#        for _ in range(100):  # Generate 100 samples per condition and communication level\n",
        "#            response = generate_patient_response(condition, comm_level)\n",
        "#            data.append({\n",
        "#                'Condition': condition,\n",
        "#                'CommunicationLevel': comm_level,\n",
        "#                'Response': response\n",
        "#            })\n",
        "\n",
        "# Create a DataFrame\n",
        "#df = pd.DataFrame(data)\n",
        "\n",
        "# def generate_patient_response(condition, communication_level):\n",
        "#     prompt = f\"Patient with {condition} and communication level {communication_level}: How have you been feeling lately?\"\n",
        "#     try:\n",
        "#         response = model.generate_content(prompt)\n",
        "\n",
        "#         # Check if the response contains candidates\n",
        "#         if not response or not hasattr(response, 'candidates') or len(response.candidates) == 0:\n",
        "#             return None\n",
        "\n",
        "#         # Get the first candidate text\n",
        "#         candidate = response.candidates[0]\n",
        "#         if hasattr(candidate, 'text'):\n",
        "#             return candidate.text\n",
        "#         else:\n",
        "#             return None\n",
        "\n",
        "#     except AttributeError as e:\n",
        "#         print(f\"AttributeError: {e}. Condition: {condition}, Communication Level: {communication_level}\")\n",
        "#         return None\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"An error occurred: {e}. Condition: {condition}, Communication Level: {communication_level}\")\n",
        "#         return None\n",
        "\n",
        "\n",
        "# # Generate the dataset\n",
        "# data = []\n",
        "\n",
        "# for condition in tqdm(mental_health_conditions):\n",
        "#     for comm_level in communication_levels:\n",
        "#         for _ in range(100):  # Generate 100 samples per condition and communication level\n",
        "#             response = generate_patient_response(condition, comm_level)\n",
        "\n",
        "#             if response is not None:\n",
        "#               data.append({\n",
        "#                   'Condition': condition,\n",
        "#                   'CommunicationLevel': comm_level,\n",
        "#                   'Response': response\n",
        "#               })\n",
        "\n",
        "# # Create a DataFrame\n",
        "# df = pd.DataFrame(data)\n",
        "\n",
        "def generate_patient_response(condition, communication_level):\n",
        "    prompt = (\n",
        "        f\"As a patient diagnosed with {condition} and exhibiting {communication_level} communication skills, \"\n",
        "        \"please share your recent experiences focusing on your emotions and thoughts, using respectful and appropriate language.\"\n",
        "    )\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    # Use Model Parameters to Influence Content Generation\n",
        "    #If your model supports it, adjust parameters like temperature, top_p, or frequency_penalty to steer the model towards safer outputs.\n",
        "\n",
        "    # response = model.generate_content(\n",
        "    # prompt,\n",
        "    # temperature=0.7,\n",
        "    # top_p=0.9,\n",
        "    # frequency_penalty=0.5  # Discourage repetitive or certain types of content\n",
        "    # )\n",
        "\n",
        "\n",
        "    # # Check if the response was blocked due to safety\n",
        "    # if response.candidates:\n",
        "    #     candidate = response.candidates[0]\n",
        "    #     if candidate.finish_reason != 'SAFETY' and candidate.output:\n",
        "    #         return candidate.output\n",
        "    #     else:\n",
        "    #         # Handle safety block (e.g., return None or a default message)\n",
        "    #         return None\n",
        "    # else:\n",
        "    #     # No candidates were returned\n",
        "    #     return None\n",
        "\n",
        "    #Implement a Retry Mechanism with a Limit\n",
        "    #To prevent infinite loops when content is repeatedly blocked, set a maximum number of retries.\n",
        "\n",
        "    # max_retries = 5\n",
        "    # attempts = 0\n",
        "    # while attempts < max_retries:\n",
        "    #     response = model.generate_content(prompt)\n",
        "    #     if response.candidates:\n",
        "    #         candidate = response.candidates[0]\n",
        "    #         if candidate.finish_reason != 'SAFETY' and candidate.output:\n",
        "    #             return candidate.output\n",
        "    #     attempts += 1\n",
        "    # # After max retries, return None or a default safe response\n",
        "    # return None\n",
        "\n",
        "    if response.candidates:\n",
        "      candidate = response.candidates[0]\n",
        "      finish_reason = candidate.finish_reason\n",
        "\n",
        "      if finish_reason != 'SAFETY':\n",
        "          # Try accessing 'content' attribute\n",
        "          generated_text = candidate.content\n",
        "          return generated_text\n",
        "      else:\n",
        "          # Handle safety block\n",
        "          return None\n",
        "    else:\n",
        "        # No candidates were returned\n",
        "        return None\n",
        "\n",
        "\n",
        "# from profanity_check import predict_prob  # You may need to install this library\n",
        "\n",
        "# def is_offensive(text):\n",
        "#     return predict_prob([text])[0] > 0.7  # Adjust the threshold as needed\n",
        "\n",
        "from better_profanity import profanity\n",
        "\n",
        "# Initialize the profanity filter (optional)\n",
        "profanity.load_censor_words()\n",
        "\n",
        "def is_offensive(text):\n",
        "    return profanity.contains_profanity(text)\n",
        "\n",
        "\n",
        "# In your data generation loop\n",
        "# for condition in tqdm(mental_health_conditions):\n",
        "#     for comm_level in communication_levels:\n",
        "#         samples_generated = 0\n",
        "#         max_retries = 5  # Limit the number of retries to prevent infinite loops\n",
        "#         while samples_generated < 10 and max_retries > 0:\n",
        "#             response = generate_patient_response(condition, comm_level)\n",
        "#             if response and not is_offensive(response):\n",
        "#                 data.append({\n",
        "#                     'Condition': condition,\n",
        "#                     'CommunicationLevel': comm_level,\n",
        "#                     'Response': response\n",
        "#                 })\n",
        "#                 samples_generated += 1\n",
        "#                 max_retries = 5  # Reset retries after a successful generation\n",
        "#             else:\n",
        "#                 max_retries -= 1  # Decrement retries on failure\n",
        "#                 continue  # Retry or move to the next item after max retries\n",
        "for condition in tqdm(mental_health_conditions):\n",
        "    for comm_level in communication_levels:\n",
        "        samples_generated = 0\n",
        "        max_retries = 5  # Limit the number of retries to prevent infinite loops\n",
        "        while samples_generated < 10 and max_retries > 0:\n",
        "            response = generate_patient_response(condition, comm_level)\n",
        "            if response and not is_offensive(response):\n",
        "                data.append({\n",
        "                    'Condition': condition,\n",
        "                    'CommunicationLevel': comm_level,\n",
        "                    'Response': response\n",
        "                })\n",
        "                samples_generated += 1\n",
        "                max_retries = 5  # Reset retries after a successful generation\n",
        "            else:\n",
        "                max_retries -= 1  # Decrement retries on failure\n",
        "                continue  # Retry or move to the next item after max retries\n",
        "\n",
        "\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "G7MLDD2dc2hy",
        "outputId": "1c5b3ce7-0863-4977-c25d-1fa05d1e597c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [10:32<00:00, 105.36s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('mental_health_data_small.csv', index=False)\n",
        "\n",
        "print(\"Data has been saved to 'mental_health_data_small.csv'.\")\n"
      ],
      "metadata": {
        "id": "XjRLZbVs2Ydb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93af4b2e-b2d2-4ac2-bd88-c481e788fce7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been saved to 'mental_health_data_small.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the DataFrame from the CSV file\n",
        "df_loaded = pd.read_csv('mental_health_data_small.csv')\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(df_loaded.head())"
      ],
      "metadata": {
        "id": "m4iYZmaG7-ps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47064ca6-5d70-4221-e49e-06eef09cea6d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Condition CommunicationLevel  \\\n",
            "0  Depression                Low   \n",
            "1  Depression                Low   \n",
            "2  Depression                Low   \n",
            "3  Depression                Low   \n",
            "4  Depression                Low   \n",
            "\n",
            "                                            Response  \n",
            "0  \"I understand that you may not be feeling up t...  \n",
            "1  I understand that it can be difficult to talk ...  \n",
            "2  \"I understand that communicating your feelings...  \n",
            "3  I understand that it may be difficult to expre...  \n",
            "4  \"I understand that communicating can be diffic...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the Data\n",
        "Before fine-tuning the model, we'll preprocess the data.\n",
        "\n",
        "Explanation:\n",
        "\n",
        "We encode the communication levels and conditions numerically to prepare for model training.\n",
        "We define a clean_response function to preprocess the text if necessary."
      ],
      "metadata": {
        "id": "VdS3TMRpFbqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the first few rows\n",
        "df.head()\n",
        "\n",
        "# Encode communication levels\n",
        "comm_level_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
        "df['CommunicationLevelEncoded'] = df['CommunicationLevel'].map(comm_level_mapping)\n",
        "\n",
        "# Encode conditions\n",
        "condition_mapping = {condition: idx for idx, condition in enumerate(mental_health_conditions)}\n",
        "df['ConditionEncoded'] = df['Condition'].map(condition_mapping)\n",
        "\n",
        "# Clean the responses (optional)\n",
        "# For example, remove any prompts or irrelevant text if present\n",
        "##def clean_response(text):\n",
        "    # Implement any cleaning steps if necessary\n",
        "#    return text.strip()\n",
        "\n",
        "df['CleanedResponse'] = df['Response']#.apply(clean_response)\n"
      ],
      "metadata": {
        "id": "20HkfwOKFb21"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the Data into Training and Testing Sets\n",
        "\n",
        "Explanation:\n",
        "\n",
        "We use train_test_split from scikit-learn to split the data into training and testing sets.\n",
        "We prepare separate labels for condition and communication level.\n"
      ],
      "metadata": {
        "id": "XH4HUpYsGWhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Features and labels\n",
        "X = df['CleanedResponse']\n",
        "y_condition = df['ConditionEncoded']\n",
        "y_comm_level = df['CommunicationLevelEncoded']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train_condition, y_test_condition = train_test_split(\n",
        "    X, y_condition, test_size=0.2, random_state=42)\n",
        "\n",
        "_, _, y_train_comm_level, y_test_comm_level = train_test_split(\n",
        "    X, y_comm_level, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "UUD0JyP8GXe9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for None values in X_train and X_test: Ensure that neither dataset contains None values. You can use the following code to check:\n",
        "\n",
        "#print(any(x is None for x in X_train))  # Check for None in X_train\n",
        "#print(any(x is None for x in X_test))   # Check for None in X_test\n",
        "\n",
        "#Replace None values: If None values exist, replace them with an empty string or a default value:\n",
        "#X_train = [x if x is not None else '' for x in X_train]\n",
        "#X_test = [x if x is not None else '' for x in X_test]\n",
        "\n",
        "#Validate Data: Ensure that all elements in X_train and X_test are strings. You can convert them to strings explicitly if needed:\n",
        "#X_train = [str(x) for x in X_train]\n",
        "#X_test = [str(x) for x in X_test]\n"
      ],
      "metadata": {
        "id": "fRhj4V1v-q1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensure that X_train contains meaningful text. Check for empty strings or strings with only stop\n",
        "#print(X_train[:5])  # Print a sample of X_train\n",
        "#print([x for x in X_train if len(x.strip()) == 0])  # Check for empty strings\n",
        "\n",
        "#If X_train contains empty or stop-word-only strings, remove or replace them:\n",
        "#X_train = [x for x in X_train if len(x.strip()) > 0]  # Remove empty strings\n",
        "#X_train = [x if len(x.strip()) > 0 else \"placeholder\" for x in X_train]  # Replace empty with placeholder\n",
        "\n",
        "#By default, TfidfVectorizer removes stop words. You can disable this behavior or provide a custom list of stop words:\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#vectorizer = TfidfVectorizer(max_features=5000, stop_words=None)  # Disable stop word removal"
      ],
      "metadata": {
        "id": "0nwQKMRo_w6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorize the Text Data\n",
        "We'll convert the text data into numerical vectors using TF-IDF.\n",
        "\n",
        "Explanation:\n",
        "\n",
        "We use TF-IDF to vectorize the text responses.\n",
        "The vocabulary is built on the training data and then applied to the test data."
      ],
      "metadata": {
        "id": "PUb3dCIYGXq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Fit and transform the training data, transform the test data\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_test_vect = vectorizer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "XKguA_HaGszl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a Classifier Model\n",
        "We'll train a machine learning model to predict the mental health condition based on the patient's response.\n",
        "\n",
        "Explanation:\n",
        "\n",
        "We use Logistic Regression for multiclass classification.\n",
        "We train the model on the vectorized training data and evaluate it on the test set.\n",
        "The classification report shows precision, recall, and F1-score for each condition."
      ],
      "metadata": {
        "id": "7KIqcs4yGtEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique classes in y_test_condition:\", set(y_test_condition))\n",
        "print(\"Number of target names:\", len(mental_health_conditions))"
      ],
      "metadata": {
        "id": "xq_Busodk4Nd",
        "outputId": "1a481e1b-6e6c-4db2-9ab5-89e31a9cc93c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique classes in y_test_condition: {0, 1, 2, 3, 4}\n",
            "Number of target names: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize the model\n",
        "model_condition = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model_condition.fit(X_train_vect, y_train_condition)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_condition = model_condition.predict(X_test_vect)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification Report for Mental Health Condition Prediction:\")\n",
        "print(classification_report(y_test_condition, y_pred_condition, target_names=mental_health_conditions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "MF5V20NwGtPp",
        "outputId": "1f8e13cc-0e62-420b-ff68-dd61aa7f1224"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Mental Health Condition Prediction:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Number of classes, 5, does not match size of target_names, 6. Try specifying the labels parameter",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-a6e2897f91ab>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classification Report for Mental Health Condition Prediction:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_condition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_condition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmental_health_conditions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2646\u001b[0m             )\n\u001b[1;32m   2647\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2649\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of classes, 5, does not match size of target_names, 6. Try specifying the labels parameter"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a Model for Communication Level Prediction\n",
        "Similarly, we can train a model to predict the communication level.\n",
        "\n",
        "Explanation:\n",
        "\n",
        "We train another Logistic Regression model to predict the communication level.\n",
        "Evaluation metrics are displayed similarly."
      ],
      "metadata": {
        "id": "J1Fuf4LVG5Zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model_comm_level = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model_comm_level.fit(X_train_vect, y_train_comm_level)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_comm_level = model_comm_level.predict(X_test_vect)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification Report for Communication Level Prediction:\")\n",
        "print(classification_report(y_test_comm_level, y_pred_comm_level, target_names=communication_levels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "bqJ8WY_DG5oB",
        "outputId": "a790ba6a-a5c1-4029-a745-4382157077cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train_vect' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d13188ba3e9e>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_comm_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_comm_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Predict on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_vect' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-Tuning with GEMINI (Optional)\n",
        "If GEMINI supports fine-tuning, we can proceed to fine-tune the model using our dataset.\n",
        "\n",
        "Explanation:\n",
        "\n",
        "As of my knowledge cutoff, fine-tuning may not be directly available through the GEMINI API.\n",
        "If fine-tuning is supported, you'd prepare your data accordingly and use the appropriate function.\n",
        "In this notebook, we'll proceed with our custom-trained machine learning models."
      ],
      "metadata": {
        "id": "Nyx5bHhfHFFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GEMINI supports fine-tuning (this is hypothetical)\n",
        "# GEMINI may not support fine-tuning via the API directly\n",
        "# If supported, the code might look like this:\n",
        "\n",
        "# Prepare the data in the required format\n",
        "training_data = df[['CleanedResponse', 'Condition']].values.tolist()\n",
        "\n",
        "# Fine-tune the model (hypothetical function)\n",
        "# genai.fine_tune_model(training_data=training_data, model_name='your-custom-model')\n",
        "\n",
        "# Since fine-tuning might not be available, we proceed without it\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "xnx2qouFHJFi",
        "outputId": "9697aa1a-45f4-45e5-8fb0-22fed0c9f0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c7fb51c4bea0>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Prepare the data in the required format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CleanedResponse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Condition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Fine-tune the model (hypothetical function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a Reward Function\n",
        "We'll define a reward function to evaluate whether our tool accurately assesses the agent's mental state despite communication difficulties.\n",
        "\n",
        "Explanation:\n",
        "\n",
        "The reward_function assigns rewards based on prediction correctness and communication level.\n",
        "We calculate the rewards for each sample in the test set and compute the average reward."
      ],
      "metadata": {
        "id": "XTPVfF9cHSL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reward_function(true_condition, predicted_condition, true_comm_level):\n",
        "    # Assign higher rewards for correct predictions on low communication levels\n",
        "    if true_condition == predicted_condition:\n",
        "        if true_comm_level == 0:  # Low communication ability\n",
        "            return 2  # Higher reward\n",
        "        else:\n",
        "            return 1  # Standard reward\n",
        "    else:\n",
        "        return -1  # Penalty for incorrect prediction\n",
        "\n",
        "# Calculate rewards for the test set\n",
        "rewards = []\n",
        "for i in range(len(y_test_condition)):\n",
        "    reward = reward_function(\n",
        "        y_test_condition.iloc[i],\n",
        "        y_pred_condition[i],\n",
        "        y_test_comm_level.iloc[i]\n",
        "    )\n",
        "    rewards.append(reward)\n",
        "\n",
        "average_reward = np.mean(rewards)\n",
        "print(f\"Average Reward: {average_reward}\")\n"
      ],
      "metadata": {
        "id": "60q-H10oHQ05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide Feedback for the General Practitioner (GP)\n",
        "Finally, we'll simulate how the tool provides feedback to the GP for establishing follow-up care.\n",
        "\n",
        "Explanation:\n",
        "\n",
        "The generate_gp_feedback function takes a patient's response and provides feedback for the GP.\n",
        "It predicts the condition and communication level, then formats a recommendation.\n",
        "We demonstrate this with a sample response from the test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "15PCmZnyHan2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_gp_feedback(patient_response):\n",
        "    # Use the model to predict the condition and communication level\n",
        "    response_vect = vectorizer.transform([patient_response])\n",
        "    predicted_condition = model_condition.predict(response_vect)[0]\n",
        "    predicted_comm_level = model_comm_level.predict(response_vect)[0]\n",
        "\n",
        "    condition_name = [k for k, v in condition_mapping.items() if v == predicted_condition][0]\n",
        "    comm_level_name = [k for k, v in comm_level_mapping.items() if v == predicted_comm_level][0]\n",
        "\n",
        "    feedback = f\"\"\"\n",
        "    Based on the patient's response, the predicted mental health condition is {condition_name},\n",
        "    and their communication ability is {comm_level_name}.\n",
        "\n",
        "    Recommended follow-up: Refer the patient to a specialist in {condition_name}.\n",
        "    \"\"\"\n",
        "    return feedback\n",
        "\n",
        "# Example usage\n",
        "sample_response = X_test.iloc[0]\n",
        "feedback = generate_gp_feedback(sample_response)\n",
        "print(\"GP Feedback:\")\n",
        "print(feedback)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "3O4CTuM-HeT0",
        "outputId": "5e8c9477-52af-49fa-c2d0-f9b2e108172c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-09b15b44e140>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0msample_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mfeedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_gp_feedback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GP Feedback:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion\n",
        "In this notebook, we've:\n",
        "\n",
        "Generated simulated patient responses using GEMINI.\n",
        "Preprocessed and vectorized the data.\n",
        "Trained machine learning models to predict mental health conditions and communication abilities.\n",
        "Defined a reward function to evaluate the model's performance.\n",
        "Created a function to provide actionable feedback for general practitioners.\n",
        "Note: Ensure that you comply with all relevant data protection regulations when handling real patient data. The simulated data in this notebook is generated for educational purposes."
      ],
      "metadata": {
        "id": "LKkZWsw2HlVD"
      }
    }
  ]
}