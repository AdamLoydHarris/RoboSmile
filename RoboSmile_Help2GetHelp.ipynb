{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamLoydHarris/RoboSmile/blob/main/RoboSmile_Help2GetHelp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Below is a Jupyter notebook that guides you through the process of generating simulated patient data, fine-tuning a model using Google Generative AI (GEMINI), and evaluating the model's performance in assessing mental health states. The notebook is well-documented with explanatory comments to help you understand each step.\n",
        "\n",
        "We start by installing the google-generativeai package, which provides access to Google's Generative AI models.\n",
        "We import necessary libraries:\n",
        "google.generativeai for interacting with the GEMINI API.\n",
        "pandas and numpy for data manipulation.\n",
        "tqdm for progress bars during data generation."
      ],
      "metadata": {
        "id": "pg8-WwHuFM39"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2q43Nl1GFKI1",
        "outputId": "b07ebdb6-fd50-4106-f934-8818fe69cf4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: better_profanity in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "# Install the google-generativeai package\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install -q --upgrade google-generativeai\n",
        "\n",
        "#!pip install profanity_check\n",
        "!pip install better_profanity\n",
        "\n",
        "# Import necessary libraries\n",
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "#import userdata  # Assuming you have a module to handle user data securely\n",
        "\n",
        "# Configure the API Key\n",
        "GOOGLE_API_KEY = 'AIzaSyCNyCdzpcNjEU2vFlhWpQIW0DZfFH_uqwE'\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf8_cKvb7Nwe",
        "outputId": "ac8482ec-22d0-4355-c635-ae2d654c9a58"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Simulated Patient Data\n",
        "We'll generate a dataset of simulated patients with various mental health conditions and communication abilities.\n",
        "\n",
        "We define a list of mental health conditions and communication levels.\n",
        "The generate_patient_response function creates a prompt for the GEMINI model to generate a patient's response based on the condition and communication level.\n",
        "We loop through each condition and communication level, generating 100 samples for each combination.\n",
        "The data is stored in a pandas DataFrame for easy manipulation."
      ],
      "metadata": {
        "id": "14CnVPICFaxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define mental health conditions and communication levels\n",
        "mental_health_conditions = [\n",
        "    'Depression',\n",
        "    'Anxiety',\n",
        "    'Bipolar Disorder',\n",
        "    'Schizophrenia',\n",
        "    'PTSD',\n",
        "    'OCD'\n",
        "]\n",
        "\n",
        "communication_levels = ['Low', 'Medium', 'High']\n",
        "\n",
        "\n",
        "def generate_patient_response(condition, communication_level):\n",
        "    prompt = (\n",
        "        f\"As a patient diagnosed with {condition} and exhibiting {communication_level} communication skills: please share your recent experiences focusing on your emotions and thoughts, using respectful and appropriate language.\"\n",
        "    )\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "\n",
        "\n",
        "def generate_summary_from_response(text_response):\n",
        "    pre_prompt = \"\"\"\n",
        "    I'm going to give you some text from a person that might be having some mental health distress\n",
        "    that they have trouble expressing. Here are the rules:\n",
        "    - you have to figure what the best way is to describe their problems to a mental health profesional.\n",
        "    - you should not give a formal diagnosis\n",
        "    - you must be clear, compassionate, and sympathetic.\n",
        "    - you will summarise what youve gleaned from the text for either a friend or healthcare professional\n",
        "    - Do not make things up that the patient hasn't said\n",
        "    - DO NOT MAKE THINGS UP\n",
        "    - do not put the whole message in quotatin marks\n",
        "    - do not write like like its a script, just speak like a person\n",
        "\n",
        "    Here is the text, summarize it following the rules:\\n\n",
        "    \"\"\"\n",
        "    response = model.generate_content(pre_prompt + text_response)\n",
        "    return response.text\n",
        "\n",
        "# Generate the dataset\n",
        "data = []\n",
        "\n",
        "MAX_SAMPLES = 10 #30\n",
        "\n",
        "tqdm_bar = tqdm(range(MAX_SAMPLES*len(mental_health_conditions)), desc=\"Samples retrieved\")\n",
        "\n",
        "for condition in mental_health_conditions:\n",
        "    for comm_level in communication_levels:\n",
        "        samples_generated = 0\n",
        "        max_retries = 5  # Limit the number of retries to prevent infinite loops\n",
        "        while samples_generated < MAX_SAMPLES and max_retries > 0:\n",
        "            response = generate_patient_response(condition, comm_level)\n",
        "            if response:# and not is_offensive(response):\n",
        "                summary = generate_summary_from_response(response)\n",
        "                if summary:\n",
        "                  data.append({\n",
        "                      'Condition': condition,\n",
        "                      'CommunicationLevel': comm_level,\n",
        "                      'Response': response,\n",
        "                      'Summary' : summary\n",
        "                  })\n",
        "                  samples_generated += 1\n",
        "                  max_retries = 5  # Reset retries after a successful generation\n",
        "                  tqdm_bar.update(1)\n",
        "                else:\n",
        "                  max_retries -= 1  # Decrement retries on failure\n",
        "                  continue  # Retry or move to the next item after max retries\n",
        "            else:\n",
        "                max_retries -= 1  # Decrement retries on failure\n",
        "                continue  # Retry or move to the next item after max retries\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zVO9TnifEAmv",
        "outputId": "e0dc8a08-1da7-447f-9d8f-c2aebf57aba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Samples retrieved:   0%|          | 0/60 [01:43<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ReadTimeout",
          "evalue": "HTTPConnectionPool(host='localhost', port=35199): Read timed out. (read timeout=600.0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-679792dac172>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mmax_retries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m  \u001b[0;31m# Limit the number of retries to prevent infinite loops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msamples_generated\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mMAX_SAMPLES\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmax_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_patient_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomm_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m# and not is_offensive(response):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-679792dac172>\u001b[0m in \u001b[0;36mgenerate_patient_response\u001b[0;34m(condition, communication_level)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;34mf\"As a patient diagnosed with {condition} and exhibiting {communication_level} communication skills: please share your recent experiences focusing on your emotions and thoughts, using respectful and appropriate language.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     )\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    831\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m             response = getattr(self._session, method)(\n\u001b[0m\u001b[1;32m    837\u001b[0m                 \u001b[0;34m\"{host}{uri}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    542\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    711\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_InvalidHeader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeout\u001b[0m: HTTPConnectionPool(host='localhost', port=35199): Read timed out. (read timeout=600.0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "if not df.empty:\n",
        "    df.to_csv('mental_health_data_50.csv', index=False)\n",
        "    print(\"Data has been saved successfully.\")\n",
        "else:\n",
        "    print(\"DataFrame is empty. No file saved.\")\n"
      ],
      "metadata": {
        "id": "XjRLZbVs2Ydb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we had timout problems generating the summaries and with the API in general, we will train and test with the responses from a CSV file obtained previously that has no summaries\n",
        "\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "#df_loaded = pd.read_csv('mental_health_data_50.csv')\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/AdamLoydHarris/RoboSmile/refs/heads/main/Notebooks/mental_health_data_100.csv')\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "m4iYZmaG7-ps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "501bf8f1-6b1c-446f-c9c2-4b4d249987bc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Condition CommunicationLevel  \\\n",
            "0  Depression                Low   \n",
            "1  Depression                Low   \n",
            "2  Depression                Low   \n",
            "3  Depression                Low   \n",
            "4  Depression                Low   \n",
            "\n",
            "                                            Response  \n",
            "0  **Emotions:**\\n\\n* Persistent feelings of sadn...  \n",
            "1  **Emotions:**\\n\\n* **Isolation:** I often feel...  \n",
            "2  **Emotions:**\\n\\n* **Isolation:** I often feel...  \n",
            "3  **Emotions:**\\n\\n* I feel an overwhelming sens...  \n",
            "4  **Emotions:**\\n\\n* I often feel a profound and...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the Data\n",
        "Before fine-tuning the model, we'll preprocess the data.\n",
        "\n",
        "We encode the communication levels and conditions numerically to prepare for model training.\n",
        "We define a clean_response function to preprocess the text if necessary."
      ],
      "metadata": {
        "id": "VdS3TMRpFbqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the first few rows\n",
        "df.head()\n",
        "\n",
        "# Encode communication levels\n",
        "comm_level_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
        "df['CommunicationLevelEncoded'] = df['CommunicationLevel'].map(comm_level_mapping)\n",
        "\n",
        "# Encode conditions\n",
        "condition_mapping = {condition: idx for idx, condition in enumerate(mental_health_conditions)}\n",
        "df['ConditionEncoded'] = df['Condition'].map(condition_mapping)\n",
        "\n",
        "# Clean the responses\n",
        "def clean_response(text):\n",
        "    # Implement any cleaning steps if necessary\n",
        "    return text.strip()\n",
        "\n",
        "df['CleanedResponse'] = df['Response'].apply(clean_response)\n",
        "#df['CleanedSummary'] = df['Summary'].apply(clean_response)\n"
      ],
      "metadata": {
        "id": "20HkfwOKFb21"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate our summary\n",
        "\n",
        "We will use the ROUGE metric to evaluate our summaries with regard to the source text"
      ],
      "metadata": {
        "id": "7MZmEuun7khs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "def get_rouge(hypothesis, reference):\n",
        "  rouge_scorer = Rouge()\n",
        "  score = rouge_scorer.get_scores(\n",
        "      hyps=hypothesis,\n",
        "      refs=reference,\n",
        "  )\n",
        "  return score[0][\"rouge-l\"][\"f\"]\n",
        "\n",
        "def evaluate_summary(row):\n",
        "  reference = row['CleanedResponse']\n",
        "  hypothesis = row['CleanedSummary']\n",
        "  rouge_res = get_rouge(hypothesis, reference)\n",
        "  #print(\"Input: {}\\n--------\".format(rouge_res, response.text))\n",
        "  #print(\"{} - {}\".format(rouge_res, response.text))\n",
        "  return rouge_res\n",
        "\n",
        "df[\"ROUGE\"] = df.apply(evaluate_summary)\n",
        "\n",
        "df.head()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "VWxs_qaa70DQ",
        "outputId": "4a889b02-441b-47fc-e0bc-c97c4c7fea1a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'CleanedResponse'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-84aa604a48f8>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mrouge_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ROUGE\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-84aa604a48f8>\u001b[0m in \u001b[0;36mevaluate_summary\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CleanedResponse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CleanedSummary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mrouge_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rouge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'CleanedResponse'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the Data into Training and Testing Sets\n",
        "\n",
        "We use train_test_split from scikit-learn to split the data into training and testing sets.\n",
        "We prepare separate labels for condition and communication level.\n"
      ],
      "metadata": {
        "id": "XH4HUpYsGWhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Features and labels\n",
        "X = df['CleanedResponse'] #df['CleanedSummary']\n",
        "y_condition = df['ConditionEncoded']\n",
        "y_comm_level = df['CommunicationLevelEncoded']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train_condition, y_test_condition = train_test_split(\n",
        "    X, y_condition, test_size=0.2, random_state=42)\n",
        "\n",
        "_, _, y_train_comm_level, y_test_comm_level = train_test_split(\n",
        "    X, y_comm_level, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "UUD0JyP8GXe9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorize the Text Data\n",
        "\n",
        "We use TF-IDF to vectorize the text responses.\n",
        "The vocabulary is built on the training data and then applied to the test data. With more time we would have tried sentence embeddings or similar :)"
      ],
      "metadata": {
        "id": "PUb3dCIYGXq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Fit and transform the training data, transform the test data\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_test_vect = vectorizer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "XKguA_HaGszl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a Classification Models\n",
        "We'll train a different machine learning model to predict the mental health condition based on the patient's response."
      ],
      "metadata": {
        "id": "7KIqcs4yGtEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "\n",
        "We use Logistic Regression for multiclass classification. We train the model on the vectorized training data and evaluate it on the test set.\n",
        "The classification report shows precision, recall, and F1-score for each condition."
      ],
      "metadata": {
        "id": "W-xKPwiD0ZW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique classes in y_test_condition:\", set(y_test_condition))\n",
        "print(\"Number of target names:\", len(mental_health_conditions))"
      ],
      "metadata": {
        "id": "xq_Busodk4Nd",
        "outputId": "cefabc76-3e91-42e8-8654-d557161e57f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique classes in y_test_condition: {0, 1, 2, 3, 4, 5}\n",
            "Number of target names: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we train a model for detecting the mental condition."
      ],
      "metadata": {
        "id": "WtMix01Z0l3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize the model\n",
        "model_condition = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model_condition.fit(X_train_vect, y_train_condition)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_condition = model_condition.predict(X_test_vect)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification Report for Mental Health Condition Prediction:\")\n",
        "print(classification_report(y_test_condition, y_pred_condition, target_names=mental_health_conditions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF5V20NwGtPp",
        "outputId": "c59826c1-8d05-4d3c-c60f-6178ecf867f2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Mental Health Condition Prediction:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "      Depression       0.95      1.00      0.97        53\n",
            "         Anxiety       0.92      0.99      0.95        74\n",
            "Bipolar Disorder       0.98      0.89      0.93        55\n",
            "   Schizophrenia       0.93      1.00      0.96        50\n",
            "            PTSD       1.00      0.94      0.97        68\n",
            "             OCD       1.00      0.95      0.97        60\n",
            "\n",
            "        accuracy                           0.96       360\n",
            "       macro avg       0.96      0.96      0.96       360\n",
            "    weighted avg       0.96      0.96      0.96       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train another Logistic Regression model to predict the communication level. Evaluation metrics are displayed similarly."
      ],
      "metadata": {
        "id": "J1Fuf4LVG5Zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model_comm_level = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model_comm_level.fit(X_train_vect, y_train_comm_level)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_comm_level = model_comm_level.predict(X_test_vect)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification Report for Communication Level Prediction:\")\n",
        "print(classification_report(y_test_comm_level, y_pred_comm_level, target_names=communication_levels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqJ8WY_DG5oB",
        "outputId": "d6446434-7c33-4636-b5c5-1f46f8768f9d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Communication Level Prediction:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Low       0.84      0.86      0.85       120\n",
            "      Medium       0.74      0.72      0.73       113\n",
            "        High       0.88      0.89      0.89       127\n",
            "\n",
            "    accuracy                           0.82       360\n",
            "   macro avg       0.82      0.82      0.82       360\n",
            "weighted avg       0.82      0.82      0.82       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "9oMCqW2nCymq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "print(\"Training and Evaluating Random Forest...\")\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_vect, y_train_condition)\n",
        "\n",
        "# Make predictions\n",
        "rf_predictions = rf_model.predict(X_test_vect)\n",
        "\n",
        "# Evaluate Random Forest\n",
        "print(\"Random Forest Classification Report for Mental Health Condition Prediction:\")\n",
        "print(classification_report(y_test_condition, rf_predictions, target_names=mental_health_conditions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4t2uo5yC1nd",
        "outputId": "c5fc7156-af2c-4b02-fdec-a4344bba0c76"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and Evaluating Random Forest...\n",
            "Random Forest Classification Report for Mental Health Condition Prediction:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "      Depression       0.95      0.98      0.96        53\n",
            "         Anxiety       0.92      0.99      0.95        74\n",
            "Bipolar Disorder       0.98      0.93      0.95        55\n",
            "   Schizophrenia       0.92      0.98      0.95        50\n",
            "            PTSD       1.00      0.94      0.97        68\n",
            "             OCD       1.00      0.95      0.97        60\n",
            "\n",
            "        accuracy                           0.96       360\n",
            "       macro avg       0.96      0.96      0.96       360\n",
            "    weighted avg       0.96      0.96      0.96       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "HZAYVmlZGn8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "print(\"\\nTraining and Evaluating XGBoost...\")\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=42)\n",
        "xgb_model.fit(X_train_vect, y_train_condition)\n",
        "\n",
        "# Make predictions\n",
        "xgb_predictions = xgb_model.predict(X_test_vect)\n",
        "\n",
        "# Evaluate XGBoost\n",
        "print(\"XGBoost Classification Report for Mental Health Condition Prediction:\")\n",
        "print(classification_report(y_test_condition, xgb_predictions, target_names=mental_health_conditions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmAVH33QLkSf",
        "outputId": "ac83e6cd-efee-460f-8a71-e4f2b9ef6e91"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and Evaluating XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [19:05:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Classification Report for Mental Health Condition Prediction:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "      Depression       0.91      0.96      0.94        53\n",
            "         Anxiety       0.96      0.97      0.97        74\n",
            "Bipolar Disorder       0.89      0.91      0.90        55\n",
            "   Schizophrenia       0.98      0.98      0.98        50\n",
            "            PTSD       0.98      0.96      0.97        68\n",
            "             OCD       1.00      0.95      0.97        60\n",
            "\n",
            "        accuracy                           0.96       360\n",
            "       macro avg       0.95      0.96      0.95       360\n",
            "    weighted avg       0.96      0.96      0.96       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Neighbours (KNN, K=3)"
      ],
      "metadata": {
        "id": "EYMIhNKYC2Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "print(\"Training and Evaluating KNN...\")\n",
        "# Define the KNN model (choose k=5 as a default)\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train_vect, y_train_condition)\n",
        "\n",
        "# Make predictions\n",
        "knn_predictions = knn_model.predict(X_test_vect)\n",
        "\n",
        "# Evaluate KNN\n",
        "print(\"KNN Classification Report for Mental Health Condition Prediction:\")\n",
        "print(classification_report(y_test_condition, knn_predictions, target_names=mental_health_conditions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FylF267G0Zg",
        "outputId": "77356635-c71f-45f6-9588-79bd69d3f55c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and Evaluating KNN...\n",
            "KNN Classification Report for Mental Health Condition Prediction:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "      Depression       0.89      0.94      0.92        53\n",
            "         Anxiety       0.88      0.91      0.89        74\n",
            "Bipolar Disorder       0.85      0.84      0.84        55\n",
            "   Schizophrenia       0.96      0.98      0.97        50\n",
            "            PTSD       0.97      0.88      0.92        68\n",
            "             OCD       0.95      0.97      0.96        60\n",
            "\n",
            "        accuracy                           0.92       360\n",
            "       macro avg       0.92      0.92      0.92       360\n",
            "    weighted avg       0.92      0.92      0.92       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machines (SVM, one-vs-rest)"
      ],
      "metadata": {
        "id": "Rv13di6pC5t3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_model = SVC(kernel='linear', decision_function_shape='ovo', random_state=42)\n",
        "svm_model.fit(X_train_vect, y_train_condition)\n",
        "\n",
        "# Make predictions\n",
        "svm_predictions = svm_model.predict(X_test_vect)\n",
        "\n",
        "# Evaluate SVM\n",
        "print(\"SVM Classification Report for Mental Health Condition Prediction:\")\n",
        "print(classification_report(y_test_condition, svm_predictions, target_names=mental_health_conditions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFwFFqR4DYCk",
        "outputId": "9014b446-26f2-4ca5-aa91-94038ee64fe2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classification Report for Mental Health Condition Prediction:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "      Depression       0.95      1.00      0.97        53\n",
            "         Anxiety       0.95      1.00      0.97        74\n",
            "Bipolar Disorder       1.00      0.89      0.94        55\n",
            "   Schizophrenia       0.93      1.00      0.96        50\n",
            "            PTSD       1.00      0.96      0.98        68\n",
            "             OCD       1.00      0.97      0.98        60\n",
            "\n",
            "        accuracy                           0.97       360\n",
            "       macro avg       0.97      0.97      0.97       360\n",
            "    weighted avg       0.97      0.97      0.97       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the best results are obtained by the SVM model, reaching 97% macro f1-score recall, specially appreciated in the mental health domain (where a false positive can be rechecked but a false negative can be dangerous)"
      ],
      "metadata": {
        "id": "1UXH0QOWN2Tc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Future idea: Fine-Tuning with GEMINI\n",
        "\n",
        "If GEMINI supports fine-tuning, we can proceed to fine-tune the model using our dataset.\n",
        "\n",
        "As of my knowledge cutoff, fine-tuning may not be directly available through the GEMINI API.\n",
        "If fine-tuning is supported, you'd prepare your data accordingly and use the appropriate function.\n",
        "In this notebook, we'll proceed with our custom-trained machine learning models."
      ],
      "metadata": {
        "id": "Nyx5bHhfHFFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GEMINI supports fine-tuning (this is hypothetical)\n",
        "# GEMINI may not support fine-tuning via the API directly\n",
        "# If supported, the code might look like this:\n",
        "\n",
        "# Prepare the data in the required format\n",
        "training_data = df[['CleanedResponse', 'Condition']].values.tolist()\n",
        "\n",
        "# Fine-tune the model (hypothetical function)\n",
        "# genai.fine_tune_model(training_data=training_data, model_name='your-custom-model')\n",
        "\n",
        "# Since fine-tuning might not be available, we proceed without it\n"
      ],
      "metadata": {
        "id": "xnx2qouFHJFi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a Reward Function. We'll define a reward function to evaluate whether our tool accurately assesses the agent's mental state despite communication difficulties.\n",
        "\n",
        "The reward_function assigns rewards based on prediction correctness and communication level.\n",
        "We calculate the rewards for each sample in the test set and compute the average reward."
      ],
      "metadata": {
        "id": "XTPVfF9cHSL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reward_function(true_condition, predicted_condition, true_comm_level):\n",
        "    # Assign higher rewards for correct predictions on low communication levels\n",
        "    if true_condition == predicted_condition:\n",
        "        if true_comm_level == 0:  # Low communication ability\n",
        "            return 2  # Higher reward\n",
        "        else:\n",
        "            return 1  # Standard reward\n",
        "    else:\n",
        "        return -1  # Penalty for incorrect prediction\n",
        "\n",
        "# Calculate rewards for the test set\n",
        "rewards = []\n",
        "for i in range(len(y_test_condition)):\n",
        "    reward = reward_function(\n",
        "        y_test_condition.iloc[i],\n",
        "        y_pred_condition[i],\n",
        "        y_test_comm_level.iloc[i]\n",
        "    )\n",
        "    rewards.append(reward)\n",
        "\n",
        "average_reward = np.mean(rewards)\n",
        "print(f\"Average Reward: {average_reward}\")\n"
      ],
      "metadata": {
        "id": "60q-H10oHQ05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e575fd04-3b64-444a-c609-7543c6841436"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Reward: 1.2194444444444446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide Feedback for the General Practitioner (GP). We would simulate how the tool provides feedback to the GP for establishing follow-up care.\n",
        "\n",
        "The generate_gp_feedback function takes a patient's response and provides feedback for the GP.\n",
        "It predicts the condition and communication level, then formats a recommendation.\n",
        "We demonstrate this with a sample response from the test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "15PCmZnyHan2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_gp_feedback(patient_response):\n",
        "    # Use the model to predict the condition and communication level\n",
        "    response_vect = vectorizer.transform([patient_response])\n",
        "    predicted_condition = model_condition.predict(response_vect)[0]\n",
        "    predicted_comm_level = model_comm_level.predict(response_vect)[0]\n",
        "\n",
        "    condition_name = [k for k, v in condition_mapping.items() if v == predicted_condition][0]\n",
        "    comm_level_name = [k for k, v in comm_level_mapping.items() if v == predicted_comm_level][0]\n",
        "\n",
        "    feedback = f\"\"\"\n",
        "    Based on the patient's response, the predicted mental health condition is {condition_name},\n",
        "    and their communication ability is {comm_level_name}.\n",
        "\n",
        "    Recommended follow-up: Refer the patient to a specialist in {condition_name}.\n",
        "    \"\"\"\n",
        "    return feedback\n",
        "\n",
        "# Example usage\n",
        "sample_response = X_test.iloc[0]\n",
        "feedback = generate_gp_feedback(sample_response)\n",
        "print(\"GP Feedback:\")\n",
        "print(feedback)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O4CTuM-HeT0",
        "outputId": "a890074b-b203-409c-b01d-f63de5b48cb1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GP Feedback:\n",
            "\n",
            "    Based on the patient's response, the predicted mental health condition is OCD,\n",
            "    and their communication ability is Low.\n",
            "\n",
            "    Recommended follow-up: Refer the patient to a specialist in OCD.\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "In this notebook, we've:\n",
        "\n",
        "*   Generated simulated patient responses using GEMINI.\n",
        "*   Preprocessed and vectorized the data.\n",
        "*   Trained machine learning models to predict mental health conditions and communication abilities.\n",
        "\n",
        "Also, added functionality for future steps:\n",
        "*   Defined a reward function to evaluate the model's performance.\n",
        "*   Created a function to provide actionable feedback for general practitioners."
      ],
      "metadata": {
        "id": "LKkZWsw2HlVD"
      }
    }
  ]
}